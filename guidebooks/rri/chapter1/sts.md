# Science , Technology, and Society

In April 1945, Michael Polanyi—a chemist and sociologist of science—and Bertrand Russell—a philosopher and logician—were speaking on a radio programme about the practical implications of the famous formula, $E = mc^2$.

They were asked whether the formula had any practical applications for society, but neither could provide an answer.

Three months later the Manhattan project dropped the first of their three atomic bombs!

```{image} /images/graphics/bomb.jpeg
:alt: A 3d rendering of an atomic bomb
:align: center
```

{cite:p}`bridgstock1998` draws attention to this story, because it was used originally by Polanyi, in his essay, 'The Republic of Science' {cite:p}`polanyi1962`, to suggest that the practical and societal outcomes of pure scientific research were often unforeseen and unintended. The problem with this suggestion is that it implies that scientists cannot be held accountable or exercise any real responsibility for the consequences of their research—a troubling implication if true.

However, the definitions we have already encountered suggest that science, technology, and society are closely interconnected, and that RRI requires reflection upon the myriad ways that science and technology can impact and shape social norms and practices. Responsibility arises from this relationship, but if the impacts or consequences are unforeseeable and often unanticipated, then the principles of RRI may be too demanding.

Fortunately, the implications of Polanyi's example are narrow in scope. The following thought experiment will help us illustrate how.

Imagine a CEO of a large manufacturing company is approached by one of her scientific advisors and informed that a project that she has proposed will require an environmental impact assessment before it can proceed. The CEO dismisses this and orders that the project continue without the assessment. Furthermore, she callously proclaims that she does not care what the environmental consequences of the project may be. All she is interested in is making as much profit as possible. As it turns out, the project ends up causing vast amounts of pollution that cause irreparable harm to the nearby flora and fauna, and also affects the health of a community living downstream of the manufacturing plant. The CEO is, rightfully, held accountable, both morally and legally, and is prosecuted when her dismissal of the impact assessment is uncovered.

Few would take issue with the consequences for the CEO. She had a responsibility to ensure her company's processes operated in a safe and ethical manner, but chose to wilfully neglect this responsibility in spite of receiving advice from her staff.

Now, let's alter some of the details of the case but keep the logical structure the same.

This time, everything about the thought experiment remains the same except for the outcomes of the project. Instead, the project causes no harm. In fact, the efficiency of the new project actually reduces the company's emissions and leads to more sustainable operations.

There is no need to worry about accountability in this instance, as no harms occurred. But does the CEO deserve praise for her actions? This question is less likely to have a consensus among the answers.

Those that believe the CEO deserves no praise are likely to point to the fact that she did not carry out her due diligence or reflect upon the possible consequences of her project. She chose to ignore the suggestion of undertaking an environmental impact assessment, and, therefore, did not act in a responsible manner. She was unable to anticipate any harms or benefits because she did not gather the appropriate evidence. Neither did she act with deliberate intention, but instead acted in a careless manner. In short, she was lucky that the outcomes were positive.

Polanyi may be right to suggest that the societal impacts or consequences of some pure scientific research is hard to anticipate. This is especially true for the more distant effects. Consider again the long-term impact of the Human Genome Project, which is arguably still affecting current research. But this is not the case for all research or innovation projects.

There is no question about whether scientists, researchers, and developers have *some* responsibility for the applications of their research. This must be true for them to be *praised* for the positive outcomes, which they often are, and also to be held accountable and *blamed* for the negative consequences when they occur. The question is, rather, when they should receive praise and blame. While we will not try to answer this question, we will look at some of the practical ways that scientists, researchers, and developers can take responsibility for the social impacts of their research, in order to maximise the potential opportunities and minimise the possible harms associated with their work.

## Risk and Impact Assessments

At the [start of this chapter](responsibility.md) we looked at a definition of RRI from {cite:p}`vonschomberg2011`. Let's look at another one, this time from the European Commission:

```{tabbed} European Commission
> Responsible research and innovation is an approach that anticipates and assesses potential implications and societal expectations with regard to research and innovation, with the aim to foster the design of inclusive and sustainable research and innovation. {cite:p}`europeancommission2014`
```

```{tabbed} René von Schomberg
> “Responsible Research and Innovation is a transparent, interactive process by which societal actors and innovators become mutually responsive to each other with a view on the (ethical) acceptability, sustainability and societal desirability of the innovation process and its marketable products (in order to allow a proper embedding of scientific and technological advances in our society).” {cite:p}`vonschomberg2011`
```

There are many similarities between the two definitions, but they also emphasise different aspects through their choice of terminology. For instance, the definition from the European Commission refers to anticipation and assessment, Likely to emphasise the need for formal risk or impact assessment. There are many types of risk and impact assessments that can be carried out, such as safety and risk assessments, equality impact assessments, human rights impact assessments, and, of course, data protection impact assessments.

The necessity of such assessments will be familiar to those who work in commercial or public sector organisations, but less so to those in academic institutions. Typically they are carried out for compliance reasons. However the structured nature of such assessments can also support more ethical forms of reflection and anticipation.

It is not necessary to present an overview of all the different impact assessments that could be useful within the context of responsible research and innovation. However, the following resources are available for those who wish to explore some of them in more detail.

Instead, we will focus on a process that is central to almost all forms of risk or impact assessments: stakeholder participation.

## Inclusive and Deliberative Stakeholder Participation

:::{seealso} Why should stakeholders be included in a research or innovation project? :::

There are *at least* two answers that can be given to this question?

1. To identify and meet stakeholder or user needs
2. To ensure that possible harms that could arise are identified and addressed

The first of these answers is reminiscent of a typical stage in product design. For example, a design committee for a new product may reach out to possible consumers/users, to identify what they think about a range of prototypes or to gather feedback about a possible feature. Such processes have what we can refer to as 'instrumental value'. That is, the purpose of including stakeholders or users is directed towards the benefit it brings to the project. Their participation serves an instrumental role in obtaining a goal, such as developing a product that is more likely to sell.

A similar claim could also be made for the second answer. However, in this instance, the focus is on mitigating risks or harms, as opposed to realising benefits. Here, the stakeholders or users still play an instrumental role in securing a goal of the project team (e.g., to ensure no harm is caused by their research or project).

However, stakeholder engagement has a further *intrinsic* value, which is more clearly exposed when science and technology are properly situated in a social context. Framed as a third answer that appropriates the language of the above two definitions:

3. Stakeholder participation is a necessary component of responsible design, development, and deployment. It recognises the need for stakeholders and innovators to become mutually responsive to each other in an inclusive and deliberative process that aims at realising sustainable research and innovation practices that promote the social good.

This answer helps to expose a limitation of the instrumental perspective. That is, stakeholder engagement is about more than the identification of potential risks and benefits; just as RRI is about more than the avoidance of gross misconduct (e.g., plagiarism, fabrication/falsification of results, developing obviously dangerous technologies). We will, of course, look at many of the practical mechanisms by which harms can be minimised (e.g., bias mitigation). And, many of these will require the involvement of myriad stakeholders. However, it is important at the outset to recognise the right that all members of society have to participate in science and innovation, especially insofar as it relates to how science pursues goals that shape and alter social norms and expectations. And, to be clear, it is a *right*—one which is captured in Article 27 of the Universal Declaration of Human Rights:

> Everyone has the right freely to participate in the cultural life of the community, to enjoy the arts and to share in scientific advancement and its benefits.

RRI relies on both the organic and creative nature of the human mind as much as it does the meticulous standards of the scientific method. Involving diverse stakeholders can prevent a sort of *cognitive staleness* or group-think arising within teams when it comes to problem solving. But more importantly, participation in research and innovation can improve trust, buy-in, and promote scientific understanding and literacy. This goes beyond a narrow instrumental value to a broader social and ethical value. It is, arguably, part of the motivation behind famous ladder of public engagement {cite:p}`arnstein1969`.

```{figure} images/graphics/ladder.jpeg
---
align: center
name: ladder-of-engagement
alt: Sherry Arnstein's Ladder of Engagement
---
Sherry Arnstein's Ladder of Engagement (Reprinted from Wikimedia Commons—https://commons.wikimedia.org/wiki/File:Ladder_of_citizen_participation,_Sherry_Arnstein.tiff).
```

Responsible participation goes beyond informing or consultation (i.e., monological forms of engagement). It aims at dialogical engagement that is representative of meaningful partnerships and, hopefully, sustainable forms of devolution of power where members of society are equipped with the capabilities necessary to have legitimate control over the outcomes of scientific research or technological innovation.
