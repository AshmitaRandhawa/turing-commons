# Responsible Data Science and AI

> What separates responsible data science and AI from responsible research and innovation more generally?

This is the question that this section seeks to answer. 

We saw in the [previous chapter](../chapter2/index.md) how RRI can be defined or operationalised through reference to principles or concepts that emphasise the need for ethical reflection on possible social harms and benefits, supported by inclusive participation of affected stakeholders.

Responsible data science and AI shares this emphasis, but can be refined by considering more specific principles that are geared towards the particular harms and benefits associated with data science and AI.

## SAFE-D Principles

According to {cite:p}`mittelstadt2019', in 2019 there were at least 84 statements that provided ''high-level principles, values and other tenets to guide the ethical development, deployment and governance of AI''.
By now there are surely many, many more!

In response to this proliferation of principles, some have attempted to distil and condense the myriad documents, in order to identify commonalities and extract a unified list of shared principles {cite:p}`jobin2019,floridi2019`.
However, regardless of which set of principles we start with, one thing remains the same: good principles should support ongoing reflection and deliberation; they are not decision procedures in their own right.
This point is sometimes lost in the ensuing debate about which set of principles should be used or adhered to.
But, what matters is that the set of principles should (a) be responsive to the actual harms and benefits that matter to the communities of affected inividuals, (b) be underwritten by a set of shared values, which support and motivate dialogue between stakeholders, and (c) serve as *starting points* in a wider process of reflection and deliberation.

To that end, we will make reference to the following set of principles that we call the 'SAFE-D principles':

- Safety
- Accountability
- Fairness
- Explainability
- Data Quality, Integrity, Protection and Privacy

These principles are grounded in comprehensive research and understanding of human rights and data protection law, as well as applied ethics of data and AI.
Each principles is either motivated by a specific set of harms that have been uncovered and exposed, responsive to a set or well-documented risks that arise in the context of data science and AI, or oriented towards the sustainable, ethical, and responsible use of data-driven technologies.
Let's look at each one in turn.

### Safety

Safety is of paramount importance for ensuring the sustainable development, deployment, and use of an AI system.
From a technical perspective, this requires the system to be secure, robust, and reliable.
And from a social sustainability perspective, this requires the practices behind the system’s production and use to be informed by ongoing consideration of the risk of exposing affected rights-holders to harms, continuous reflection on project context and impacts, ongoing stakeholder engagement and involvement, and change monitoring of the system from its deployment through to its retirement or deprovisioning.

### Accountability

Accountability can include specific forms of process transparency (e.g., as enacted through process logs or external auditing) that may be necessary for mechanisms of redress, or broader processes of responsible governance that seek to establish clear roles of responsibility where transparency may be inappropriate (e.g., confidential projects).

### Fairness

Fairness is inseparably connected with sociolegal conceptions of equity and justice, which may emphasize a variety of features such as non-discrimination, equitable outcomes, or procedural fairness through bias mitigation, but also social and economic equality, diversity, and inclusiveness.

### Explainability

Explainability is a key condition for autonomous and informed decision-making in situations where AI systems interact with or influence human judgement and decision-making.
Explainability goes beyond the ability to merely interpret the outcomes of an AI system; it also depends on the ability to provide an accessible and relevant information base about the processes behind the outcome.

### Data Quality, Integrity, Protection and Privacy

Data quality, integrity, protection and privacy must all be established to be confident that a research or innovation project has been designed, developed, and deployed in a responsible manner.

- 'Data Quality' captures the static properties of data, such as whether they are (a) *relevant* to and *representative* of the domain and use context, (b) *balanced* and *complete* in terms of how well the dataset represents the underlying data generating process, and (c) *up-to-date* and *accurate* as required by the project.
- ‘Data Integrity' refers to more dynamic properties of data stewardship, such as how a dataset evolves over the course of a project lifecycle. In this manner, data integrity requires (a) *contemporaneous* and *attributable* records from the start of a project (e.g., process logs; research statements), (b) ensuring *consistent* and *verifiable* means of data analysis or processing during development, and (c) taking steps to establish *findable*, *accessible*, *interoperable*, and *reusable* records towards the end of a project’s lifecycle.[^FAIR]
- ‘Data protection and privacy' reflect ongoing developments and priorities as set out in relevant legislation and regulation of data practices as they pertain to fundamental rights and freedoms, democracy, and the rule of law. For example, the right for data subjects to have inaccurate personal data rectified or erased.{cite:p}`ico2021`

[^FAIR]: These are known as the FAIR principles ([read more here](https://www.go-fair.org/fair-principles/)).