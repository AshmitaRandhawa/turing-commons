
@article{arnstein1969,
  title = {A {{Ladder Of Citizen Participation}}},
  author = {Arnstein, Sherry R.},
  year = {1969},
  month = jul,
  journal = {Journal of the American Institute of Planners},
  volume = {35},
  number = {4},
  pages = {216--224},
  issn = {0002-8991},
  doi = {10.1080/01944366908977225},
  abstract = {The heated controversy over ``citizen participation,'' ``citizen control'', and ``maximum feasible involvement of the poor,'' has been waged largely in terms of exacerbated rhetoric and misleading euphemisms. To encourage a more enlightened dialogue, a typology of citizen participation is offered using examples from three federal social programs: urban renewal, anti-poverty, and Model Cities. The typology, which is designed to be provocative, is arranged in a ladder pattern with each rung corresponding to the extent of citizens' power in determining the plan and/or program.}
}

@misc{aronson2018,
  title = {A {{Word About Evidence}}: 4. {{Bias}}\textemdash Etymology and Usage},
  shorttitle = {A {{Word About Evidence}}},
  author = {Aronson, Jeff},
  year = {2018},
  journal = {Catalogue of Bias},
  howpublished = {https://catalogofbias.org/2018/04/10/a-word-about-evidence-4-bias-etymology-and-usag/},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/5LNNHN5N/a-word-about-evidence-4-bias-etymology-and-usag.html}
}

@article{ashmore2019,
  title = {Assuring the {{Machine Learning Lifecycle}}: Desiderata, {{Methods}}, and {{Challenges}}},
  shorttitle = {Assuring the {{Machine Learning Lifecycle}}},
  author = {Ashmore, Rob and Calinescu, Radu and Paterson, Colin},
  year = {2019},
  month = may,
  journal = {arXiv:1905.04223 [cs, stat]},
  eprint = {1905.04223},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  abstract = {Machine learning has evolved into an enabling technology for a wide range of highly successful applications. The potential for this success to continue and accelerate has placed machine learning (ML) at the top of research, economic and political agendas. Such unprecedented interest is fuelled by a vision of ML applicability extending to healthcare, transportation, defence and other domains of great societal importance. Achieving this vision requires the use of ML in safety-critical applications that demand levels of assurance beyond those needed for current ML applications. Our paper provides a comprehensive survey of the state-of-the-art in the assurance of ML, i.e. in the generation of evidence that ML is sufficiently safe for its intended use. The survey covers the methods capable of providing such evidence at different stages of the machine learning lifecycle, i.e. of the complex, iterative process that starts with the collection of the data used to train an ML component for a system, and ends with the deployment of that component within the system. The paper begins with a systematic presentation of the ML lifecycle and its stages. We then define assurance desiderata for each stage, review existing methods that contribute to achieving these desiderata, and identify open challenges that require further research.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning,Computer Science - Software Engineering,Statistics - Machine Learning},
  file = {/Users/cburr/Zotero/storage/9BAJE732/Ashmore et al. - 2019 - Assuring the Machine Learning Lifecycle Desiderat.pdf;/Users/cburr/Zotero/storage/QIH9HG6C/Ashmore et al. - 2019 - Assuring the Machine Learning Lifecycle Desiderat.pdf}
}

@misc{ball2020,
  title = {The Real Story of {{Cambridge Analytica}} and {{Brexit}} | {{The Spectator}}},
  author = {Ball, James},
  year = {2020},
  month = oct,
  abstract = {In July 2018, Elizabeth Denham \textendash{} the woman in charge of enforcing the UK's laws on data protection \textendash{} appeared on the Today programme, and made a stark allegation. 'In 2014 and 2015, the Facebook platform allowed an app\ldots{} that ended up harvesting 87 million profiles of users around the world that was...},
  howpublished = {https://www.spectator.co.uk/article/were-there-any-links-between-cambridge-analytica-russia-and-brexit-},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/3TG38H22/were-there-any-links-between-cambridge-analytica-russia-and-brexit-.html}
}

@article{barnhart1989,
  title = {{{DOE Human Genome Project}}},
  author = {Barnhart, Benjamin},
  year = {1989},
  journal = {Human Genome Quarterly},
  volume = {1},
  number = {1},
  file = {/Users/cburr/Zotero/storage/JU5MNAFY/Vol1No1.pdf}
}

@book{beauchamp2013,
  title = {Principles of Biomedical Ethics},
  author = {Beauchamp, Tom L and Childress, James F},
  year = {2013},
  edition = {Seventh},
  publisher = {{Oxford University Press}},
  address = {{New York, N.Y.}},
  isbn = {978-0-19-992458-5},
  langid = {english},
  keywords = {Ethics; Medical,Medical ethics}
}

@book{bridgstock1998,
  title = {Science, Technology, and Society: An Introduction},
  shorttitle = {Science, Technology, and Society},
  author = {Bridgstock, Martin},
  year = {1998},
  publisher = {{Cambridge University Press}},
  address = {{Cambridge, U.K. ; New York}},
  isbn = {978-0-521-58320-6 978-0-521-58735-8},
  langid = {english},
  lccn = {Q175.5 .S3738 1998},
  keywords = {Science,Science and state,Social aspects,Technology,Technology and state},
  file = {/Users/cburr/Zotero/storage/AEF9P33J/Bridgstock - 1998 - Science, technology, and society an introduction.pdf}
}

@article{burr2019,
  title = {Can {{Machines Read}} Our {{Minds}}?},
  author = {Burr, Christopher and Cristianini, Nello},
  year = {2019},
  month = sep,
  journal = {Minds and Machines},
  volume = {29},
  number = {3},
  pages = {461--494},
  issn = {0924-6495, 1572-8641},
  doi = {10.1007/s11023-019-09497-4},
  abstract = {We explore the question of whether machines can infer information about our psychological traits or mental states by observing samples of our behaviour gathered from our online activities. Ongoing technical advances across a range of research communities indicate that machines are now able to access this information, but the extent to which this is possible and the consequent implications have not been well explored. We begin by highlighting the urgency of asking this question, and then explore its conceptual underpinnings, in order to help emphasise the relevant issues. To answer the question, we review a large number of empirical studies, in which samples of behaviour are used to automatically infer a range of psychological constructs, including affect and emotions, aptitudes and skills, attitudes and orientations (e.g. values and sexual orientation), personality, and disorders and conditions (e.g. depression and addiction). We also present a general perspective that can bring these disparate studies together and allow us to think clearly about their philosophical and ethical implications, such as issues related to consent, privacy, and the use of persuasive technologies for controlling human behaviour.},
  copyright = {All rights reserved},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/7929S8WK/Burr and Cristianini - 2019 - Can Machines Read our Minds.pdf;/Users/cburr/Zotero/storage/E4IS9IWE/Burr and Cristianini - 2019 - Can Machines Read our Minds.pdf}
}

@misc{burr2021,
  title = {Ethical {{Assurance}}: A Practical Approach to the Responsible Design, Development, and Deployment of Data-Driven Technologies},
  author = {Burr, Christopher and Leslie, David},
  year = {2021},
  publisher = {{Under Review}}
}

@article{burton2020,
  title = {A Systematic Review of Algorithm Aversion in Augmented Decision Making},
  author = {Burton, Jason W. and Stein, Mari-Klara and Jensen, Tina Blegind},
  year = {2020},
  month = apr,
  journal = {Journal of Behavioral Decision Making},
  volume = {33},
  number = {2},
  pages = {220--239},
  issn = {0894-3257, 1099-0771},
  doi = {10.1002/bdm.2155},
  abstract = {Despite abundant literature theorizing societal implications of algorithmic decision making, relatively little is known about the conditions that lead to the acceptance or rejection of algorithmically generated insights by individual users of decision aids. More specifically, recent findings of algorithm aversion\textemdash the reluctance of human forecasters to use superior but imperfect algorithms\textemdash raise questions about whether joint humanalgorithm decision making is feasible in practice. In this paper, we systematically review the topic of algorithm aversion as it appears in 61 peer-reviewed articles between 1950 and 2018 and follow its conceptual trail across disciplines. We categorize and report on the proposed causes and solutions of algorithm aversion in five themes: expectations and expertise, decision autonomy, incentivization, cognitive compatibility, and divergent rationalities. Although each of the presented themes addresses distinct features of an algorithmic decision aid, human users of the decision aid, and/or the decision making environment, apparent interdependencies are highlighted. We conclude that resolving algorithm aversion requires an updated research program with an emphasis on theory integration. We provide a number of empirical questions that can be immediately carried forth by the behavioral decision making community.},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/RE2XGAC7/Burton et al_2020_A systematic review of algorithm aversion in augmented decision making.pdf}
}

@article{cadwalladr2017,
  title = {The Great {{British Brexit}} Robbery: How Our Democracy Was Hijacked},
  shorttitle = {The Great {{British Brexit}} Robbery},
  author = {Cadwalladr, Carole},
  year = {2017},
  month = may,
  journal = {The Guardian},
  issn = {0261-3077},
  abstract = {A shadowy operation involving big data, billionaire friends of Trump and the disparate forces of the Leave campaign heavily influenced the result of the EU referendum. Is our electoral process still fit for purpose?},
  chapter = {Technology},
  langid = {british},
  keywords = {Article 50,Big data,Brexit,Data protection,Dominic Cummings,European Union,Facebook,Foreign policy,Politics,Technology,UK news},
  file = {/Users/cburr/Zotero/storage/4Y392D4H/the-great-british-brexit-robbery-hijacked-democracy.html}
}

@misc{duff-brown2017,
  title = {The Shameful Legacy of {{Tuskegee}} Syphilis Study Still Impacts {{African}}-{{American}} Men Today},
  author = {{Duff-Brown}, Beth},
  year = {2017},
  journal = {Stanford Health Policy},
  howpublished = {https://healthpolicy.fsi.stanford.edu/news/researchers-and-students-run-pilot-project-oakland-test-whether-tuskegee-syphilis-trial-last},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/A6CC49DM/researchers-and-students-run-pilot-project-oakland-test-whether-tuskegee-syphilis-trial-last.html}
}

@misc{europeancommission2014,
  type = {Text},
  title = {Responsible Research \& Innovation},
  author = {European Commission},
  year = {2014},
  month = apr,
  journal = {Horizon 2020},
  abstract = {Responsible research \& innovation},
  howpublished = {https://ec.europa.eu/programmes/horizon2020/en/h2020-section/responsible-research-innovation},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/Z7TITN8R/responsible-research-innovation.html}
}

@article{floridi2019,
  title = {A {{Unified Framework}} of {{Five Principles}} for {{AI}} in {{Society}}},
  author = {Floridi, Luciano and Cowls, Josh},
  year = {2019},
  month = jun,
  journal = {Harvard Data Science Review},
  doi = {10.1162/99608f92.8cd550d1},
  abstract = {Artificial Intelligence (AI) is already having a major impact on society. As a result, many organizations have launched a wide range of initiatives to establish ethical principles for the adoption of socially beneficial AI. Unfortunately, the sheer volume of proposed principles threatens to overwhelm and confuse. How might this problem of `principle proliferation' be solved? In this paper, we report the results of a fine-grained analysis of several of the highest-profile sets of ethical principles for AI. We assess whether these principles converge upon a set of agreed-upon principles, or diverge, with significant disagreement over what constitutes `ethical AI.' Our analysis finds a high degree of overlap among the sets of principles we analyze. We then identify an overarching framework consisting of five core principles for ethical AI. Four of them are core principles commonly used in bioethics: beneficence, non-maleficence, autonomy, and justice. On the basis of our comparative analysis, we argue that a new principle is needed in addition: explicability, understood as incorporating both the epistemological sense of intelligibility (as an answer to the question `how does it work?') and in the ethical sense of accountability (as an answer to the question: `who is responsible for the way it works?'). In the ensuing discussion, we note the limitations and assess the implications of this ethical framework for future efforts to create laws, rules, technical standards, and best practices for ethical AI in a wide range of contexts.},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/CZZWYA6H/Floridi_Cowls_2019_A Unified Framework of Five Principles for AI in Society.pdf}
}

@techreport{ico2020,
  title = {Explaining Decisions Made with {{AI}}},
  author = {ICO and Alan Turing Institute},
  year = {2020},
  month = may,
  institution = {{ICO \& Alan Turing Institute}},
  file = {/Users/cburr/Zotero/storage/GA3GCNA6/ICO_Alan Turing Institute_2020_Explaining decisions made with AI.pdf}
}

@misc{ico2021,
  title = {Guide to {{Data Protection}}},
  author = {ICO},
  year = {2021},
  month = oct,
  publisher = {{ICO}},
  abstract = {This guide is for data protection officers and others who have day-to-day responsibility for data protection. It is aimed at small and medium-sized organisations, but it may be useful for larger organisations too.},
  howpublished = {https://ico.org.uk/for-organisations/guide-to-data-protection/},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/EFI4BF9T/guide-to-data-protection.html}
}

@article{jobin2019,
  title = {The Global Landscape of {{AI}} Ethics Guidelines},
  author = {Jobin, Anna and Ienca, Marcello and Vayena, Effy},
  year = {2019},
  month = sep,
  journal = {Nature Machine Intelligence},
  volume = {1},
  number = {9},
  pages = {389--399},
  issn = {2522-5839},
  doi = {10.1038/s42256-019-0088-2},
  abstract = {In the past five years, private companies, research institutions and public sector organizations have issued principles and guidelines for ethical artificial intelligence (AI). However, despite an apparent agreement that AI should be `ethical', there is debate about both what constitutes `ethical AI' and which ethical requirements, technical standards and best practices are needed for its realization. To investigate whether a global agreement on these questions is emerging, we mapped and analysed the current corpus of principles and guidelines on ethical AI. Our results reveal a global convergence emerging around five ethical principles (transparency, justice and fairness, non-maleficence, responsibility and privacy), with substantive divergence in relation to how these principles are interpreted, why they are deemed important, what issue, domain or actors they pertain to, and how they should be implemented. Our findings highlight the importance of integrating guideline-development efforts with substantive ethical analysis and adequate implementation strategies.},
  file = {/Users/cburr/Zotero/storage/DUE9LGHC/Jobin et al_2019_The global landscape of AI ethics guidelines.pdf}
}

@article{kang2018,
  title = {Facebook {{Says Cambridge Analytica Harvested Data}} of {{Up}} to 87 {{Million Users}}},
  author = {Kang, Cecilia and Frenkel, Sheera},
  year = {2018},
  month = apr,
  journal = {The New York Times},
  issn = {0362-4331},
  abstract = {Mr. Zuckerberg, Facebook's chief executive, will appear before multiple congressional committees next week. It is part of the company's efforts to be more open about its work.},
  chapter = {Technology},
  langid = {american},
  keywords = {Cambridge Analytica,Data-Mining and Database Marketing,Facebook Inc,Presidential Election of 2016,Russian Interference in 2016 US Elections and Ties to Trump Associates,Trump; Donald J,United States Politics and Government,Zuckerberg; Mark E},
  file = {/Users/cburr/Zotero/storage/IZ9WFSI5/mark-zuckerberg-testify-congress.html}
}

@article{kosinski2013,
  title = {Private Traits and Attributes Are Predictable from Digital Records of Human Behavior},
  author = {Kosinski, M. and Stillwell, D. and Graepel, T.},
  year = {2013},
  month = apr,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {110},
  number = {15},
  pages = {5802--5805},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1218772110},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/MF2MBLQF/Kosinski et al_2013_Private traits and attributes are predictable from digital records of human.pdf}
}

@article{mcguire2020,
  title = {The Road Ahead in Genetics and Genomics},
  author = {McGuire, Amy L. and Gabriel, Stacey and Tishkoff, Sarah A. and Wonkam, Ambroise and Chakravarti, Aravinda and Furlong, Eileen E. M. and Treutlein, Barbara and Meissner, Alexander and Chang, Howard Y. and {L{\'o}pez-Bigas}, N{\'u}ria and Segal, Eran and Kim, Jin-Soo},
  year = {2020},
  month = oct,
  journal = {Nature Reviews Genetics},
  volume = {21},
  number = {10},
  pages = {581--596},
  issn = {1471-0056, 1471-0064},
  doi = {10.1038/s41576-020-0272-6},
  abstract = {In celebration of the 20th anniversary of Nature Reviews Genetics, we asked 12 leading researchers to reflect on the key challenges and opportunities faced by the field of genetics and genomics. Keeping their particular research area in mind, they take stock of the current state of play and emphasize the work that remains to be done over the next few years so that, ultimately, the benefits of genetic and genomic research can be felt by everyone.},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/8KMY2U9J/McGuire et al. - 2020 - The road ahead in genetics and genomics.pdf}
}

@article{mittelstadt2019a,
  title = {Principles Alone Cannot Guarantee Ethical {{AI}}},
  author = {Mittelstadt, Brent},
  year = {2019},
  month = nov,
  journal = {Nature Machine Intelligence},
  volume = {1},
  number = {11},
  pages = {501--507},
  issn = {2522-5839},
  doi = {10.1038/s42256-019-0114-4},
  abstract = {Artificial intelligence (AI) ethics is now a global topic of discussion in academic and policy circles. At least 84 public\textendash private initiatives have produced statements describing high-level principles, values and other tenets to guide the ethical development, deployment and governance of AI. According to recent meta-analyses, AI ethics has seemingly converged on a set of principles that closely resemble the four classic principles of medical ethics. Despite the initial credibility granted to a principled approach to AI ethics by the connection to principles in medical ethics, there are reasons to be concerned about its future impact on AI development and governance. Significant differences exist between medicine and AI development that suggest a principled approach for the latter may not enjoy success comparable to the former. Compared to medicine, AI development lacks (1) common aims and fiduciary duties, (2) professional history and norms, (3) proven methods to translate principles into practice, and (4) robust legal and professional accountability mechanisms. These differences suggest we should not yet celebrate consensus around high-level principles that hide deep political and normative disagreement.},
  file = {/Users/cburr/Zotero/storage/YJY786MV/Mittelstadt_2019_Principles alone cannot guarantee ethical AI.pdf}
}

@book{morozov2013,
  title = {To Save Everything, Click Here: Technology, Solutionism and the Urge to Fix Problems That Don't Exist},
  shorttitle = {To Save Everything, Click Here},
  author = {Morozov, Evgeny},
  year = {2013},
  publisher = {{Allen Lane}},
  address = {{London}},
  isbn = {978-0-241-95769-1 978-1-84614-548-3 978-1-84614-549-0},
  langid = {english}
}

@techreport{nationalcommission1979,
  title = {The {{Belmont Report}} - {{Ethical Principles}} and {{Guidelines}} for the {{Protection}} of {{Human Subjects}} of {{Research}}},
  author = {National Commission},
  year = {1979},
  month = apr,
  pages = {10},
  address = {{United States}},
  institution = {{The National Commission for the Protection of Human Subjects of Biomedical and Behavioral Research}},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/R5BTVNFL/National Commission_1979_The Belmont Report - Ethical Principles and Guidelines for the Protection of.pdf}
}

@misc{nhgri2021,
  title = {Human {{Genome Project FAQ}}},
  author = {NHGRI},
  year = {2021},
  journal = {National Human Genome Research Institute},
  abstract = {Explore frequently asked questions and answers about the Human Genome Project and its impact on the field of genomics.},
  howpublished = {https://www.genome.gov/human-genome-project/Completion-FAQ},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/7Y5NSLDQ/Completion-FAQ.html}
}

@article{obermeyer2019,
  title = {Dissecting Racial Bias in an Algorithm Used to Manage the Health of Populations},
  author = {Obermeyer, Ziad and Powers, Brian and Vogeli, Christine and Mullainathan, Sendhil},
  year = {2019},
  month = oct,
  journal = {Science},
  volume = {366},
  number = {6464},
  pages = {447--453},
  publisher = {{American Association for the Advancement of Science}},
  doi = {10.1126/science.aax2342},
  file = {/Users/cburr/Zotero/storage/DN5D6YII/Obermeyer et al_2019_Dissecting racial bias in an algorithm used to manage the health of populations.pdf}
}

@article{owen2012,
  title = {Responsible Research and Innovation: From Science in Society to Science for Society, with Society},
  shorttitle = {Responsible Research and Innovation},
  author = {Owen, R. and Macnaghten, P. and Stilgoe, J.},
  year = {2012},
  month = dec,
  journal = {Science and Public Policy},
  volume = {39},
  number = {6},
  pages = {751--760},
  issn = {0302-3427, 1471-5430},
  doi = {10.1093/scipol/scs093},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/VYHXLDNM/Owen et al_2012_Responsible research and innovation.pdf}
}

@book{owen2013,
  title = {Responsible Innovation},
  editor = {Owen, Richard and Bessant, J. R. and Heintz, Maggy},
  year = {2013},
  publisher = {{Wiley}},
  address = {{Chichester, West Sussex, United Kingdom}},
  isbn = {978-1-118-55140-0 978-1-118-55139-4 978-1-118-55141-7},
  langid = {english},
  lccn = {HD45},
  keywords = {Environmental aspects,Moral and ethical aspects,New products,Research; Industrial,Technological innovations},
  file = {/Users/cburr/Zotero/storage/Y8VAQRAM/Owen et al_2013_Responsible innovation.pdf}
}

@article{polanyi1962,
  title = {The {{Republic}} of Science: Its Political and Economic Theory},
  shorttitle = {The {{Republic}} of Science},
  author = {Polanyi, Michael},
  year = {1962},
  journal = {Minerva},
  volume = {1},
  number = {1},
  pages = {54--73},
  issn = {0026-4695, 1573-1871},
  doi = {10.1007/BF01101453},
  langid = {english}
}

@article{reverby2001,
  title = {More {{Than Fact}} and {{Fiction}}: Cultural {{Memory}} and the {{Tuskegee Syphilis Study}}},
  shorttitle = {More {{Than Fact}} and {{Fiction}}},
  author = {Reverby, Susan M.},
  year = {2001},
  month = sep,
  journal = {The Hastings Center Report},
  volume = {31},
  number = {5},
  pages = {22},
  issn = {00930334},
  doi = {10.2307/3527701},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/NCDCCXKF/Reverby - 2001 - More Than Fact and Fiction Cultural Memory and th.pdf}
}

@article{spence2013,
  title = {Are Antidepressants Overprescribed?},
  author = {Spence, Des and Reid, Ian C},
  year = {2013},
  journal = {BMJ},
  volume = {346},
  pages = {16--17},
  file = {/Users/cburr/Zotero/storage/JPRLJX2Q/Spence_Reid_2013_Are antidepressants overprescribed.pdf}
}

@article{svoboda2020,
  title = {Deep Learning Delivers Early Detection},
  author = {Svoboda, Elizabeth},
  year = {2020},
  journal = {Nature},
  volume = {587},
  number = {S20-22},
  pages = {3},
  doi = {10.1038/d41586-020-03157-9},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/FQUJC4TR/Stolle - Deep learning delivers early detection.pdf}
}

@book{sweenor2020,
  title = {{{ML Ops}}: Operationalizing {{Data Science}}},
  shorttitle = {{{ML Ops}}},
  author = {Sweenor, David and Hillion, Steven and Rope, Dan and Kannabiran, Dev and Hill, Thomas and O'Connell, Michael},
  year = {2020},
  publisher = {{O'Reilly}},
  abstract = {More than half of the analytics and machine learning (ML) models created by organizations today never make it into production. Instead, many of these ML models do nothing more than provide static insights in a slideshow. If they aren't truly operational, these models can't possibly do what you've trained them to do. This report introduces practical concepts to help data scientists and application engineers operationalize ML models to drive real business change. Through lessons based on numerous projects around the world, six experts in data analytics provide an applied four-step approach-Build, Manage, Deploy and Integrate, and Monitor-for creating ML-infused applications within your organization. You'll learn how to: Fulfill data science value by reducing friction throughout ML pipelines and workflows Constantly refine ML models through retraining, periodic tuning, and even complete remodeling to ensure long-term accuracy Design the ML Ops lifecycle to ensure that people-facing models are unbiased, fair, and explainable Operationalize ML models not only for pipeline deployment but also for external business systems that are more complex and less standardized Put the four-step Build, Manage, Deploy and Integrate, and Monitor approach into action.},
  langid = {english}
}

@misc{ukri2021,
  title = {Responsible Innovation},
  author = {UKRI},
  year = {2021},
  howpublished = {https://www.ukri.org/about-us/policies-standards-and-data/good-research-resource-hub/responsible-innovation/},
  langid = {american},
  file = {/Users/cburr/Zotero/storage/QPZLBVSD/responsible-innovation.html}
}

@book{vonschomberg2011,
  title = {Towards {{Responsible Research}} and {{Innovation}} in the {{Information}} and {{Communication Technologies}} and {{Security Technologies Fields}}},
  author = {Von Schomberg, Ren{\'e}},
  year = {2011},
  publisher = {{Publications Office of the European Union}},
  isbn = {978-92-79-20404-3}
}

@article{weaver2018,
  title = {Facebook Scandal: I Am Being Used as Scapegoat \textendash{} Academic Who Mined Data},
  shorttitle = {Facebook Scandal},
  author = {Weaver, Matthew},
  year = {2018},
  month = mar,
  journal = {The Guardian},
  issn = {0261-3077},
  abstract = {Cambridge University researcher Aleksandr Kogan says he is being unfairly blamed by Facebook and Cambridge Analytica},
  chapter = {UK news},
  langid = {british},
  keywords = {Cambridge Analytica,Facebook,Privacy,Social networking,Technology,UK news,University of Cambridge},
  file = {/Users/cburr/Zotero/storage/AYM857FS/facebook-row-i-am-being-used-as-scapegoat-says-academic-aleksandr-kogan-cambridge-analytica.html}
}

@article{wong2005,
  title = {The {{Discovery}} of {{Fluoxetine Hydrochloride}} ({{Prozac}})},
  author = {Wong, David T. and Perry, Kenneth W. and Bymaster, Frank P.},
  year = {2005},
  month = sep,
  journal = {Nature Reviews Drug Discovery},
  volume = {4},
  number = {9},
  pages = {764--774},
  issn = {1474-1776, 1474-1784},
  doi = {10.1038/nrd1821},
  abstract = {In the early 1970s, evidence of the role of serotonin (5-hydroxytryptamine or 5-HT) in depression began to emerge and the hypothesis that enhancing 5-HT neurotransmission would be a viable mechanism to mediate antidepressant response was put forward. On the basis of this hypothesis, efforts to develop agents that inhibit the uptake of 5-HT from the synaptic cleft were initiated. These studies led to the discovery and development of the selective serotoninreuptake inhibitor fluoxetine hydrochloride (Prozac; Eli Lilly), which was approved for the treatment of depression by the US FDA in 1987. Here, we summarize this research and discuss the many challenges that we encountered during the development of fluoxetine hydrochloride, which has now been widely acknowledged as a breakthrough drug for depression.},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/LDCRWDKN/Wong et al_2005_The Discovery of Fluoxetine Hydrochloride (Prozac).pdf}
}

@article{yesley2008,
  title = {What's {{ELSI}} Got to Do with It? Bioethics and the {{Human Genome Project}}},
  shorttitle = {What's {{ELSI}} Got to Do with It?},
  author = {Yesley, Michael S.},
  year = {2008},
  month = mar,
  journal = {New Genetics and Society},
  volume = {27},
  number = {1},
  pages = {1--6},
  issn = {1463-6778, 1469-9915},
  doi = {10.1080/14636770701843527},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/SNMF3EP7/Yesley - 2008 - What's ELSI got to do with it Bioethics and the H.pdf}
}

@article{zwart2014,
  title = {Adapt or Perish? Assessing the Recent Shift in the {{European}} Research Funding Arena from `{{ELSA}}' to `{{RRI}}'},
  shorttitle = {Adapt or Perish?},
  author = {Zwart, Hub and Landeweerd, Laurens and {van Rooij}, Arjan},
  year = {2014},
  month = dec,
  journal = {Life Sciences, Society and Policy},
  volume = {10},
  number = {1},
  pages = {11},
  issn = {2195-7819},
  doi = {10.1186/s40504-014-0011-x},
  abstract = {Two decades ago, in 1994, in the context of the 4th EU Framework Programme, ELSA was introduced as a label for developing and funding research into the ethical, legal and social aspects of emerging sciences and technologies. Currently, particularly in the context of EU funding initiatives such as Horizon2020, a new label has been forged, namely Responsible Research and Innovation (RRI). What is implied in this metonymy, this semantic shift? What is so new about RRI in comparison to ELSA? First of all, for both labels, the signifier (S) was introduced in a top-down manner, well before the concept that was signified by it (s) had acquired a clear and stable profile. In other words, the signifier preceded (and helped or helps to shape) the research strategies actually covered by these labels (the precedence of the signifier over the signified: S/s). Moreover, the newness of RRI does not reside in its interactive and anticipatory orientation, as is suggested by authors who introduced the term, but rather in its emphases on social-economic impacts (valorisation, employment and competitiveness).},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/ZWY6FUDC/Zwart et al. - 2014 - Adapt or perish Assessing the recent shift in the.pdf}
}


